{
  "default_provider": "openai",
  "temperature": 0.8,
  "openai_model": "gpt-4o",
  "local_model": "qwen3-30b-a3b",
  "local_host": "http://localhost",
  "local_port": 1234
}